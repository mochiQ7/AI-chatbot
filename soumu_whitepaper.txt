第3章　デジタルテクノロジーの変遷


　技術の発展は、人間の能力を拡張し、できることを強化してきた。人間等の知的活動をコンピュータにより再現する人工知能（Artificial Intelligence：AI）は、70年以上の開発の歴史のなかで進化を続け、企業活動、国民生活に浸透しつつある。特に2022年頃から急速に普及した生成AIは、その進化の飛躍的な例と言える。生成AIは、人間のように文章や画像を生成し、多岐にわたるタスクを自律的にこなすことができる革新的な技術である。これにより、広告やマーケティング、コンテンツ制作をはじめ様々なビジネスにおいて大きな変革がもたらされている。我々の生活においても、自然言語による対話インターフェースがますます普及し、スマートスピーカーやチャットボットが私たちの日常に溶け込み、生活を大きく変えている。また、AIはXR（拡張現実）、ロボティクス等の他の技術・サービスと組み合わされることで、より一層の発展が期待されている。例えば、生成AIを用いたXR技術により、臨場感のある仮想空間を提供することで、教育やエンターテイメントの分野で新たな価値体験を生み出している。また、AIを搭載したロボットが、製造業から介護など様々な分野で活躍し、作業の自動化や人々の生活の支援に貢献している。
　こうしたAI、XR等情報通信技術（ICT）・デジタルを利用したテクノロジー（以下「デジタルテクノロジー」という。）は、この先さらに私たちの社会・経済活動を変革していくと期待されている。一方で、こうした技術の進化には課題やリスクも伴う。生成AIの急速な進化は、同時にプライバシー侵害やデータの流出、偽・誤情報の流通・拡散といったリスクを生じさせ、世界的に規制・ルールの議論が進められている。生成AIはじめデジタルテクノロジーの可能性・リスクがこれまでになく注目されている今、課題・リスクに対処しながら、デジタルテクノロジーの開発・活用を進め、企業活動・国民生活といった社会全体の利益に資する取組が必要とされている。こうした認識のもと、令和6年版情報通信白書では、特集テーマとしてデジタルテクノロジーの変遷、現状と課題、今後の展望を概観した上で、デジタルテクノロジーと“共に生きていく”ために必要な取組を取り上げている。

第1節 AI進展の経緯と生成AIのインパクト

1. AI進展の経緯
　AI（人工知能）の歴史は1950年代から始まり、何度かブームと冬の時代を繰り返してきた。探索・推論から始まった第1次AIブームは、音声認識等が組み込まれた第2次AIブームを経て、第3次AIブームとしてディープラーニング（深層学習）をはじめとした革新的な技術が登場し、社会で実用され得るAIが開発されて社会に浸透していった。2022年頃からの生成AIの急速な普及により、現在は第4次AIブームに入ったとも言われている。

 第1～3次AIブームと冬の時代

ア　第1次AIブーム（1950年代後半～1960年代）：推論・探索の時代
　AIという言葉は、1956年に開催されたダートマス会議にて、アメリカの大学教授であったJ. McCarthyにより提唱された。人工知能の概念が確立し、科学者たちにAIという言葉が認知されるようになり、「推論」と「探索」の研究を中心に1960年代からAIの研究開発が活発化した。「推論」は、人間の思考過程を記号で表現し実行するもの、「探索」は、目的達成のために手順や選択肢を調べ、最適な解決策を見つけ出すもので、解くべき問題をコンピュータに適した形で記述し、探索木などの手法によって解を提示するものである。しかしながら、コンピュータの性能面で計算能力やデータ処理には限界があり、人間の知能のモデル化が困難であったため、当時のAIは「トイ・プロブレム」と呼ばれる簡単なパズルや迷路のような問題しか解くことができず、その実用化には課題があり、次第に冬の時代を迎えた。

イ　第2次AIブーム（1980年代から1990年代）：知識の時代
　1980年代には、コンピュータの高性能化が進み、エキスパートシステム(特定の問題に対して専門知識を持ち専門家のように事象の推論や判断ができるようになったコンピューターシステム)の登場により、各国でAIの研究開発が再び活発化した。ただし、コンピュータに学習させるデータ量が膨大であったため、当時のコンピュータの性能では処理ができず、専門家の知識の一部を模倣するに留まり、複雑な問題への対処ができないなどの課題があった。さらに、学習データを人間の手でコンピュータが理解できるように記述する必要があり、大変な労力を必要とした。そのため、AIの研究は再び冬の時代を迎えた。

ウ　第3次AIブーム（2000年代～）：機械学習の時代
　1990年代にウェブサイトが公開され、2000年代に入ると家庭向けにもネットワークが普及しはじめ、データ流通量が飛躍的に増加し、研究に使用できるデータを大量に入手することができるようになった。さらに、コンピュータの演算処理能力が向上したことにより、膨大な情報（ビッグデータ）の処理が可能となったことが大きな要因となり、機械学習が進化し、今日に至る第3次AIブームを迎えた。機械学習の手法の1つであるディープラーニング（深層学習）は、AIのプログラムに人間の脳の仕組みをシミュレートさせるニューラルネットワークという考え方を発展させた技術である。ディープラーニングにより、画像認識や自然言語処理、シミュレーションなどができるようになり、カメラの画像から人間の顔を識別することや、ロボットの自律運転の最適化などへの活用が広がった。

2 生成AIのインパクト

1 生成AIの急速な進化と普及
　ディープラーニングの基盤技術により、AIの性能が飛躍的に向上したことで、様々なコンテンツを生成できるAIが誕生した。「生成AI」は、テキスト、画像、音声などを自律的に生成できるAI技術の総称であり、2022年のOpenAIによる対話型AI“ChatGPT”の発表を契機に、特に注目された分野である。ChatGPTは、わずか5日で100万ユーザーを獲得し、さらに公開から2か月後にはユーザー数が1億人を突破するという、これまでのオンラインサービスなどと比較しても驚異的なスピードでユーザー数が拡大している。OpenAI以外にも、大手企業からスタートアップ企業まで多くの企業が生成AIの開発を発表し、世界的な開発競争が起こっている。
　生成AIは、ユーザー側の調整やスキルなしに自然な言語で指示を出すだけで容易に活用できるものであり、テキスト、画像、映像等の多様な形式（マルチモーダル）のアウトプットが取得できるものである。
　このブームの背景として、複数の要因が挙げられる。まず、ディープラーニング（深層学習）やトランスフォーマーモデルの開発・大規模化により、自然言語処理や画像生成などのタスクにおけるモデルの精度が飛躍的に向上した。そして、膨大な量のデータを用いてトレーニングされ、様々なタスクに適用可能な知識を獲得した基盤モデル（Foundation Model）や大規模言語モデル（LLM）の登場により、新たなタスクに対応するためにモデルを再トレーニングする必要がなくなり、開発や利用が大幅に容易化されるとともに、AIがより複雑なタスクをこなせるようになり、その有用性が広く認知された。さらに、クラウドコンピューティングの発展やGPU(Graphics Processing	Unit。元々グラフィックス処理用に開発されたプロセッサだが、高い並列処理能力によりAIの深層学習のような大規模な計算処理を行うのに適している)の進化により計算資源が拡充されるとともにソースコードの公開（オープンソース化）によりAIの開発や利用が一般の開発者や企業にも開かれ、より広範な分野での活用が可能になったことも一因と言える。また、使いやすいユーザーインターフェース（UI）、API（Application Programming Interface）による提供が行われたことで、AIとの対話がより身近なものとなり、AIを利用して情報を取得したり、タスクを実行したりする際に、より直感的で使いやすい方法を享受できるようになった。高い汎用性・マルチモーダル機能を通じてAIが単一のタスクに限定されず、様々なデータ形式や入力に対応し、多様なタスクを同時に処理できるようになったことで、その有用性が一層高まった。また、人間の意図・価値観に合わせてAIを振る舞わせる仕組み（いわゆるAIアライメント）の取組が進んだことも挙げられる。AIが人間と協調して働く環境が整い、多くの業界でAIの導入が促進された。

2 生成AIによる経済効果
　生成AIの登場により、我々の知的活動は大きく影響を受け、従来AIが適用しづらかった業務領域も含めて、コンテンツ制作、カスタマーサポート、建設分野等様々な業務領域での業務の変革が可能となる。「生成AIの出現は、恐らく人類史上有数の革命といっても過言ではない。企業がセキュリティ上のリスクを恐れて活用しないことこそが最大のリスクであり、むしろ自社が次の時代の生成AIファースト企業になるつもりでAI活用を進めていくべき」とも言われている。
　2023年3月17日、OpenAIとペンシルバニア大学が発表した論文によれば、80%の労働者が、彼らの持つタスクのうち少なくとも10%が大規模言語モデルの影響を受け、そのうち19%の労働者は、50%のタスクで影響を受ける。なかでも高賃金の職業、参入障壁の高い業界（データ処理系、保険、出版、ファンドなど）ではLLMの影響が大きいと予測されている。一方で、生成AIによって大きなビジネス機会を引き出す可能性もある。ボストンコンサルティンググループの分析によると、生成AIの市場規模について、2027年に1,200億ドル規模になると予想されている。最も大きな市場は「金融・銀行・保険」で、次に「ヘルスケア」、「コンシューマー」と続く。




第2節 AIの進化に伴い発展するテクノロジー

　前節で振り返ったAIの進化は、他のテクノロジーにも影響を及ぼしている。特に第3次AIブームにおけるディープラーニング（深層学習）の発展はXRを用いた仮想空間サービス、サービスロボット、自動運転等の開発に寄与し、また、生成AIの登場によってよりそれらの高度化を支えている。
AIが実際のサービスにおいて果たす機能には、「識別」「予測」「実行」という大きく3種類があるとされる。それぞれの機能を利活用する場面は、製造や運送といったあらゆる産業分野に及びうる。例えば、車両の自動運転であれば、これは画像認識・音声認識・状況判断・経路分析など様々な機能を、運輸分野に適した形で組み合わせて実用化したものである。ロボティクスにおいても、同様に複数の機能を組み合わせて実用化がなされている。ここでは、生成AIを組み込むことでさらなる実用化が進んでいる仮想空間（メタバース・デジタルツイン）、ロボティクス、自動運転の動向について取り上げる。

 1 仮想空間（メタバース・デジタルツイン）
　メタバースとは、インターネット上に仮想的につくられた、いわばもう1つの世界であり、利用者は自分の代わりとなるアバターを操作し、他者と交流するものである。仮想空間でありながら、メタバース上で購入した商品が後日自宅に届くなど、現実世界と連動したサービスも試験的に始まっているほか、仮想的なワークスペースとしてBtoBでの活用への広がりも期待されている。また、現実空間を仮想空間に再現する概念として「デジタルツイン（Digital Twin）」がある。デジタルツインとは、現実世界から集めたデータを基に仮想空間上に現実世界の要素を双子（ツイン）のように再現・構築し、様々なシミュレーションを行う技術である。メタバースとデジタルツインは、それらが存在する空間が仮想空間である点は共通であるが、その空間に存在するものが実在しているものを再現しているかどうかを問わないメタバースに対して、デジタルツインは、シミュレーションを行うためのソリューションという位置づけであるため、現実世界を再現している点が異なる。また、メタバースは、現実にはない空間でアバターを介して交流したり、ゲームをしたりというコミュニケーションが用途とされることが多いのに対して、デジタルツインは、現実世界では難しいようなシミュレーションを実施するために使われることが多い。メタバースの市場規模は、2022年の461億ドルから2030年には5,078億ドルまで拡大すると予測されている。
　生成AIにより、2D画像・3Dモデルの自動生成やプログラム作成支援など、メタバース上の創作活動における一部の過程を簡略化することができる。これにより、技術・知識的なハードルが下がり、利用者の拡大につながることが期待されている。また、敵対的生成ネットワーク（GAN：Generative Adversarial Networks）などの機械学習を用いることで、デザイン経験のない人でも自分のアバター等を作ることができ、仮想空間の中に巨大な経済圏が誕生する可能性を秘めている。

2 ロボティクス
　ロボットの開発は、1960年代に産業用として始まり、人間の手助けや危険な作業の代替として工業用途や軍事目的に利用された。1990年代からは、工場等における産業用途だけでなく、介護や清掃、配達など一般社会におけるサービス用途での開発・活用や、家庭や個人の生活においても、掃除ロボットやコンパニオンロボットなど、さまざまな用途のロボット普及が進んできた。
　世界のロボットの市場は大幅な収益増が見込まれ、2024年には428億2,000万ドルに達すると予測されている。市場内の様々なセグメントの中でも、サービス・ロボティクスは同年の市場規模が335億ドルと予測され、優位を占めると予想される。この分野は、2024年から2028年までの年平均成長率（CAGR）が11.25％と、安定した成長が見込まれ、市場規模は2028年までに655.9億ドルに達すると推定される。
　ロボットの開発・利用の拡大と人工知能（AI）の発展は相互に関わり合いながら進展してきた。ロボットは、センサ（感知／識別）、知能・制御系（判断）、駆動系（行動）の3つの要素技術を有する知能化した機械システムと捉えられており、AIのディープラーニングをベースに強化学習を組み合わせることで、識別の能力が飛躍的に上がり、ロボットに備わっているカメラやセンサから大量のデータを収集し、分析することが可能になった。生産工場などの現場では、品質検査や設備の予知保全などにすでにAIが活用されている。また、介護ロボットや接客ロボットの実用化も進んできている。音声認識技術と自然言語生成技術により、家庭用ロボットなどで人間がロボットと自然に対話を行えるようにもなってきた。
　さらに、生成AIを行動生成AIとして、判断や駆動系にも使う試みがなされている。言語や画像などマルチモーダルな情報を解釈できる生成AIが、ロボットのカメラ映像などから周囲の状況を判断し、ユーザーからの指示を達成できるよう、ロボットの物理的な動作を繰り出すというものである。ただし、ロボットのフィジカルな動きにはまだ課題があり、触覚フィードバック、柔らかいハードウェアの開発や安全な力制御などの研究が重要になると考えられ、社会での実用化にはまだ時間がかかる。通常、ロボットを動かすにはプログラミングが必要であるが、今後、生成AIが人との対話を通じて自らプログラミングができるようになれば、人の言葉を理解して即座にプログラミングし、ロボットを制御する未来も期待される。

3 自動運転技術
　自律的な自動運転技術においては、システムが行う認知、判断、操作の3つのプロセスにおいてAIの技術が活用されている。AIは、車両に搭載されたカメラやセンサから得られた周辺の情報を認識処理し、通行人や障害物を避けて車両を安全に走行させる。カメラやセンサからとらえた情報をもとに、前方を走行する車両や歩行者などがどのような挙動を見せるかなどの予測や、それらを踏まえて車両をどのように制御するべきかの判断や意思決定においても生成AIが活用されている。自動車の安全運転をサポートするのも、AIの活躍が期待されている重要な役割である。さらに、生成AIによる学習機能により、高度なルート最適化が行えるようになったほか、生成AIの音声認識技術も活用されており、運転者の声で自動車に指示を出すことができる。今後の完全自動運転の実現には、画像認識だけでなく、音声などを認識し搭乗者とのコミュニケーションを行うなど、様々な部分でマルチモーダルな生成AIが必要となっており、実際、自動車に生成AIを導入する動きが増えている。世界の自動運転車の市場規模は、2021年に240億ドルを超えた。市場は今後も成長し、2026年には約620億ドルの規模に達すると予想されている。
第4章　デジタルテクノロジーの課題と現状の対応策



第1節 AIの進化に伴う課題と現状の取組
　進化してきたAIは我々の生活に便利さをもたらす一方で、活用に当たっては留意すべきリスクや課題も存在している。これまで、AI全般についても、不適切なデータや偏ったデータを学習に使用することでモデルのバイアスや誤差が増加し、予測の信頼性が低下する点や、多くの従来の機械学習モデルについてブラックボックス（透明性の欠如）となっていてその内部動作が理解しにくく、重要な意思決定の場面で問題を引き起こす可能性が指摘されていた。これに加え、生成AIが爆発的に発展・普及する中で、特有の課題・リスクも明らかになってきた。以下に生成AIが抱えるリスク・課題を技術的/社会・経済的な観点から概観する。

1 生成AIが抱える課題
　2024年4月に総務省・経済産業省が策定した「AI事業者ガイドライン（第1.0版）」では、（従来から存在する）AIによるリスクに加えて、生成AIによって顕在化したリスクについて例示している。例えば、従来から存在するAIによるリスクとして、バイアスのある結果及び差別的な結果が出力されてしまう、フィルターバブル及びエコーチェンバー現象(フィルターバブル」とは、アルゴリズムがネット利用者個人の検索履歴やクリック履歴を分析し学習することで、個々のユーザーにとっては望むと望まざるとにかかわらず見たい情報が優先的に表示され、利用者の観点に合わない情報からは隔離され、自身の考え方や価値観の「バブル（泡）」の中に孤立するという情報環境を指す。「エコーチェンバー」とは、同じ意見を持つ人々が集まり、自分たちの意見を強化し合うことで、自分の意見を間違いないものと信じ込み、多様な視点に触れることができなくなってしまう現象を指す)が生じてしまう、データ汚染攻撃のリスク（AIの学習実施時の性能劣化及び誤分類につながるような学習データの混入等）、AIの利用拡大に伴う計算リソースの拡大によるエネルギー使用量及び環境負荷(同ガイドラインにおいては、エネルギー管理にAIを導入することで、効率的な電力利用も可能となる等、AIによる環境への貢献可能性もある点も指摘されている)等が挙げられている。また、生成AIによって顕在化したリスクとしては、ハルシネーション等が挙げられる。生成AIは事実に基づかない誤った情報をもっともらしく生成することがあり、これをハルシネーション（幻覚）と呼ぶ。技術的な対策が検討されているものの完全に抑制できるものではないため、生成AIを活用する際には、ハルシネーションが起こる可能性を念頭に置き、検索を併用するなど、ユーザーは生成AIの出力した答えが正しいかどうかを確認することが望ましい。また、生成AIの利用において、個人情報や機密情報がプロンプトとして入力され、そのAIからの出力等を通じて流出してしまうリスクや、ディープフェイクによる偽画像及び偽動画といった偽・誤情報を鵜呑みにしてしまい、情報操作や世論工作に使われるといったリスク、既存の情報に基づいてAIにより生成された回答を鵜呑みにする状況が続くと、既存の情報に含まれる偏見を増幅し、不公平あるいは差別的な出力が継続/拡大する（バイアスを再生成する）リスクがあること等も指摘されている。
　同ガイドラインでは、このような「リスクの存在を理由として直ちにAIの開発・提供・利用を妨げるものではない」としたうえで、「リスクを認識し、リスクの許容性及び便益とのバランスを検討したうえで、積極的にAIの開発・提供・利用を行うことを通じて、競争力の強化、価値の創出、ひいてはイノベーションに繋げることが期待される」としている。

 1 主要なLLMの概要
　生成AIの基盤となる大規模言語モデル（LLM）の開発では、マイクロソフトやグーグルなど米国ビックテック企業などが先行している状況にある。
　しかし、日本以外の企業・研究機関がクローズに研究開発を進めたLLMを活用するだけでは、LLM構築の過程がブラックボックス化してしまい、LLMを活用する際の権利侵害や情報漏えいなどの懸念を払拭できない。日本語に強いLLMの利活用のためには、構築の過程や用いるデータが明らかな、透明性の高い安心して利活用できる国産のLLM構築が必要となる＊3。すでに日本の企業においても、独自にLLM開発に取り組んでおり、ここではその動向を紹介する。ビッグテック企業が開発したLLMと比べると、日本では、中規模モデルのLLMが開発されている傾向が見られる。

2 国産LLMの開発

ア　NICTによる国産LLMの開発
　2023年7月に、国立研究開発法人情報通信研究機構（NICT）は、ノイズに相当するテキストが少ない350GBの高品質な独自の日本語Webテキストを用いて、400億パラメータの生成系の大規模言語モデルを開発した旨を発表した。発表によれば、NICTの開発したLLMについてはファインチューニングや強化学習は未実施であり、性能面ではChatGPT等と比較できるレベルではないものの、日本語でのやり取りが可能な水準に到達しているとしており、今後は、学習テキストについて、日本語を中心として更に大規模化していくこととしている。また、GPT-3と同規模の1,790億パラメータのモデルの事前学習に取り組み、適切な学習の設定等を探索していく予定である。さらに、より大規模な事前学習用データ、大規模な言語モデルの構築に際し、ポジティブ・ネガティブ両方の要素に関して改善を図るとともに、WISDOM X、MICSUS等既存のアプリケーションやシステムの高度化等にも取り組む予定としている（2024年5月現在、NICTではさらに開発を進め、最大3,110億パラメータのLLMを開発するなど、複数種類のLLMを開発しパラメータや学習データの違いによる性能への影響等を研究している）。

イ　サイバーエージェントが開発した日本語LLM「CyberAgentLM」
　2023年5月、サイバーエージェントが最大68億パラメータの日本語LLMを開発したことを発表した。2023年11月には、より高性能な70億パラメータ、32,000トークン対応の日本語LLM「CyberAgentLM2-7B」と、チャット形式でチューニングを行った「CyberAgentLM2-7B-Chat」の種類を公開した。日本語の文章として約50,000文字相当の大容量テキストを処理可能である。商用利用が可能なApacheLicense2.0で提供されている。

ウ　日本電信電話（NTT）が開発した日本語LLM「tsuzumi」
　2023年11月にNTTが開発した、軽量かつ世界トップレベルの日本語処理能力を持つLLMモデル「tsuzumi」が発表された。「tsuzumi」のパラメータサイズは6～70億と軽量であり、クラウド提供型LLMの課題である学習やチューニングに必要なコストを低減できる。「tsuzumi」は英語と日本語に対応しているほか、視覚や聴覚などのモーダルに対応し、特定の業界や企業組織に特化したチューニングが可能である。2024年3月から商用サービスが開始されており、今後はチューニング機能の充実やマルチモーダルの実装も順次展開される見込みである。


2 生成AIが及ぼす課題

　前述のような生成AI自身が抱える制約事項のほか、生成AIの進展・普及には、それに伴う社会的・経済的な課題も多く、国内外のテック事業者、プラットフォーム事業者、業界団体や政府等による対策検討が進められている。

1 偽・誤情報の流通・拡散等の課題及び対策
　「ディープフェイク」とは、「ディープラーニング（深層学習）」と「フェイク（偽物）」を組み合わせた造語で、本物又は真実であるかのように誤って表示し、人々が発言又は行動していない言動を行っているかのような描写をすることを特徴とする、AI技術を用いて合成された音声、画像あるいは動画コンテンツのことをいう。近年、世界各国でこれらディープフェイクによる情報操作や犯罪利用が増加しており、その対策には各方面からの取組が行われているものの、いたちごっこの様相を呈している。

ア　ディープフェイクによる課題
（ア）AIにより生成された偽・誤情報の流通・拡散
　生成AIの進歩により、非常に高品質なテキスト、画像、音声、動画を生成することが可能になり、リアルで信憑性の高い偽・誤情報を作成することが可能になった。ディープフェイク技術を用いれば、実在する人物が実際には言っていないことを本当に話しているかのような動画を簡単に作成することができる。我が国でも、生成AIを利用して作られた岸田総理大臣の偽動画がSNS上で拡散した事例が発生した。2024年1月1日に発生した能登半島地震の際にも、東日本大震災の時の津波映像や静岡県熱海市で2021年に起きた大規模土石流の映像などをあたかも能登半島地震と結びつけた投稿がSNS上で多数投稿され、大量に閲覧・拡散された。2020年には、新型コロナウイルス感染症と5G電波との関係を謳う偽情報が携帯電話基地局の破壊活動を招くなど社会的影響も生じさせている。
　SNSなど様々なデジタルサービスが普及し、あらゆる主体が情報の発信者となり、インターネット上では膨大な情報やデータが流通するようになったが、このような情報過多の社会においては、供給される情報量に比して、我々が支払えるアテンションないし消費時間が希少となるため、それらが経済的価値を持って市場で流通するようになる。このことはアテンション・エコノミーと呼ばれ、プラットフォーム事業者が、受信者のアテンションを得やすい刺激的な情報を優先表示するようになるなど、経済的インセンティブ（広告収入）により偽・誤情報が発信・拡散されたり、インターネット上での炎上を助長させたりする構造となっている。
　偽・誤情報の拡散は世界的に問題となっており、2024年1月、世界経済フォーラムは、社会や政治の分断を拡大させるおそれがあるとして、今後2年間で予想される最も深刻なリスクとして「偽情報」を挙げた。特に2024年は、米国をはじめ、バングラデシュ、インドネシア、パキスタン、インド等、50か国余りで国政選挙が予定されている。既にインドネシア大統領選の際のディープフェイク動画の流布や、米大統領選の予備選の前に偽の音声でバイデン米大統領になりすます悪質な電話等、生成AIを利用したディープフェイクによる情報操作の事例が確認されている。

（イ）その他犯罪利用
　生成AIが、情報操作のみならず、犯罪に利用されるケースも増えている。米国OpenAIのチャットボット（自動会話プログラム）であるChatGPTに用いられているものと同じAIが悪用され、「悪いGPT（BadGPT）」や「詐欺GPT（FraudGPT）」と呼ばれる不正チャットボットによってフィッシング詐欺メールが量産されている。このようなハッキングツールは、OpenAIがChatGPTを公開した2022年11月の数か月後には闇サイト上で確認されるようになり、ChatGPT公開後の12か月間で、フィッシング詐欺メールは1,265％増加し、一日平均約3万1,000件のフィッシング攻撃が発生しているという試算もある。
　ディープフェイクを利用した犯罪には、AIの画像生成能力を悪用した恐喝行為もある。SNS等で共有された一般的な写真画像をAIで不適切な内容に変換し、被害者を脅迫するというもので、米国連邦捜査局（FBI）は、被害者には未成年の子供も含まれると警告している。

イ　ディープフェイクによる情報操作や犯罪利用への対策

（ア）欧州連合（EU）
　偽・誤情報に関する法規制で先行するのは欧州連合（以下「EU」という。）である。2022年11月に発効した「デジタルサービス法（The Digital Services Act）」（以下「DSA」という。）は、超大規模オンラインプラットフォーム（VLOP）などに対して、自身の提供するサービスのリスク評価（偽情報に関するものを含む）やリスク軽減措置の実施を義務付けており、違反企業には最大で世界年間売上高の6％の制裁金が科されることとなっている。実際に、EUの執行機関である欧州委員会（以下「EC」という。）は、イスラエルに対するハマス等によるテロ攻撃に関わる違法コンテンツの拡散等を踏まえ、X（旧Twitter）がDSAを遵守していない可能性があるとして、違法コンテンツの拡散への対応のほか、プラットフォーム上の情報操作への対抗措置の有効性等の領域について、2023年12月に正式な調査を開始した。プラットフォーム上の情報操作への対抗措置に関し、ECは、特に、投稿に第三者が匿名で注釈を加える「コミュニティ・ノート」という機能等の有効性に焦点を当てる方針であるとしている。2024年3月、欧州議会は、AIに関する世界初の包括的な法的枠組みと位置づける「AI法（AI Act）」の最終案を可決し、同年5月にEU理事会にて正式承認され、同法が成立した。同法は一部ディープフェイクに関する規制も含み、2026年頃には本格的に適用される見込みである。

（イ）英国
　英国では、2023年10月に発効された「オンライン安全法（Online Safety Act 2023）」に、虚偽であると知っている情報を受信者に心理的または身体的危害を与えることを意図してインターネット上で送信した者に、6か月の禁錮刑を科す内容が含まれている。特に、相手に苦痛、不安や屈辱等を与える加害意図や、自分が性的満足を得ようとする意図があったと立証されれば、最高刑が懲役2年となる。

（ウ）米国
　米国においては、2023年7月、バイデン政権が、AI開発を主導するGoogle、Meta PlatformsやOpenAI等の7社から、AIの安全性や透明性向上に取り組む自主的なコミットメントを得たと発表した。同年9月には、新たにIBM、Adobe、NVIDIA等8社が合意し、同15社はディープフェイク対策として、真贋を示す目印をデータに忍ばせて識別を可能にする「電子透かし」等、AIによる生成を識別するための技術開発を推進している。また、米国の一部の州において、ポルノや選挙活動等の特定の目的下でのディープフェイクに関する規制が見られる。例えば、カリフォルニア、テキサス、イリノイ、ニューヨーク等9州では、相手の同意の無いディープフェイクを用いたポルノ画像や動画の配布を刑事犯罪として規定しているほか、テキサス州やカリフォルニア州では、公職の候補者に対するディープフェイク等の発信に係る規制法を設けている。なお、米国連邦法においては、国防総省や全米科学財団等の連邦機関に対し、ディープフェイクを含む偽情報に関する調査研究の強化等を求める法律が制定されている。他方、民間事業者に対しては、1996年成立の「通信品位法（Communications Decency Act）」第230条（通称Section 230）において、プロバイダは第三者が発信する情報に原則として責任を負わず、有害な内容の削除に責任を問われないと規定されているが、バイデン政権では、偽・誤情報に関してプラットフォーム事業者に一定の責任を求めるよう、法改正しようとする方向で議論が行われている。

（エ）日本
　我が国におけるデジタル空間の情報流通の健全性確保に向けては、総務省が2023年11月から「デジタル空間における情報流通の健全性確保の在り方に関する検討会」を開催しており、2024年（令和6年）夏頃までに一定のとりまとめを公表予定である。
　技術的な対策としては、インターネット上のニュース記事や広告などの情報コンテンツに、発信者情報を紐付けるオリジネータープロファイル（OP、Originator Profile）技術の研究開発が進んでいる。この技術により、なりすましや改変が見える化されることで、Web利用者が透明性の高いコンテンツを閲覧できるようになる、フェイクニュースや安易な関心獲得による広告収益が得られにくくなり、適正なWebメディアやコンテンツの配信者の権利利益侵害を低減できるようになる、広告枠が設置されるWebコンテンツの発信者が明確になることで、広告主が安心して広告出稿ができるようになるといった効果が期待される。
　また、国立情報学研究所（以下「NII」という。）がフェイク技術対策に関する研究に早期から取り組んでおり、2021年9月には、AIにより生成されたフェイク顔画像を自動判定するツール「SYNTHETIQ VISION：Synthetic video detector」を開発した。これは真贋判定をしたい画像をサーバーにアップロードすると、同ツールがフェイクかどうかを判定するものである。現在NIIでは、更に進んだディープフェイク対策技術「Cyber Vaccine（サイバーワクチン）」を開発中であり、これが実現すると、真贋判定だけでなく、どこが改竄されたのか等の情報も得ることができるようになると期待されている。


2 著作権を含む知的財産権等に関する議論
　生成AIの生成物は、主に、文章、画像、音楽・音声の3種類である。これらは、大量のデータからその特徴を学習し、プロンプト（入力）に応じて適切な結果を出力する「機械学習」の手法を用いて開発されている。この際、データを収集・複製し、学習用データセットを作成したり、データセットを学習に利用して、AI（学習済みモデル）を開発することがオリジナルデータの制作者等の権利を侵害しないかという開発・学習段階の論点がある。また、生成AIを利用して画像等を生成したり、生成した画像等をアップロードして公表、生成した画像等の複製物（イラスト集など）を販売する際に、既存の画像等の作品と類似したものを使ってしまう等の場合に、既存作品の制作者の権利の侵害等になることがある（生成・利用段階の論点）。

ア　生成AIの進展・普及に伴う著作権を含む知的財産権等に関わる問題提起
　生成AIに関連する著作権や肖像権の侵害問題は国際的に注目されており、多くの訴訟が発生している。米国では、2022年11月、GitHub Copilotの開発に関連して、学習に使用しているオープンソースコードがプログラマーの著作権を侵害している可能性があるとして、Microsoft、GitHub、OpenAIに対する集団訴訟が提訴されたほか、2023年7月には、米国の作家3名がOpenAIとMeta Platformsの2社を提訴した訴訟も発生した。同集団訴訟は、ChatGPTの機械学習に作家の著作物が無断で使用されたことによる損害賠償を請求するもので、同訴訟の結果、OpenAIは学習データから著作物を削除するのではなく、著作権侵害で訴えられた場合の訴訟費用を負担することを表明することとなった。
　新聞社、通信社等のメディアでのAIの活用は慎重なものとなっている。米国のAssociated Press（AP通信）は2023年7月にOpenAIとの提携を発表し、生成AIをニュース報道に生かす方法等について共同で研究する契約を結んだが、8月にはAIを配信可能なコンテンツ作成のために使用しないとした。一方、New York TimesはAIによる記事の無断使用でOpenAIとMicrosoftを訴え、これが報道機関による初の訴訟提起となった。日本国内においても、新聞・通信各社は、生成AIによる報道記事の無断使用について、生成AIによる記事の無断使用は許容できず、根本的な法改正に向けた検討を求める意見を表明している。
　日本では、生成AI技術の発展と急速な普及に伴って権利者やAI開発者から著作権などの知的財産権の侵害に関する懸念の声が上がったことを踏まえ、2024年3月、文化審議会著作権分科会法制度小委員会において、「AIと著作権に関する考え方について」がとりまとめられるとともに、（著作権を含む）知的財産権との関係について、2024年5月、AI時代の知的財産権検討会より、「AI時代の知的財産権検討会　中間とりまとめ」が公表された。

イ　著作権を含む知的財産権等の侵害リスクに対する取組
　生成AIの利用に際しての著作権等の権利侵害対策に向けては、データ・コンテンツの権利保持者とAI事業者双方が、互いの契約の中で対応を行うこと等が考えられる。技術的には、生成AI生成物であることの表示を可能とする電子透かしの実用化や、OpenAIによる知的財産権を侵害する恐れのあるデータ・コンテンツのAI入出力を抑制する仕様の提供等がある一方で、New York Times、CNN、Bloomberg、Reuters、日本経済新聞等の国内外のメディア側も、OpenAI等AI事業者のGPTボットのブロックを行う等の対策で自衛している。
　技術を活用しながら著作権侵害の法的リスクに対してコミットする取組もある。Microsoftは、大規模言語モデル（Large Language Model：LLM）を組み込んだ自社の生産性向上ツール「Microsoft Copilot」に対する法的リスクに対して責任を負う、「Copilot Copyright Commitment」を2023年9月に発表している。Microsoft Copilotで生成した出力結果を使用して、著作権上の異議を申し立てられた場合、Microsoftが責任をとる仕組みとなっている。著作物を使用しない、あるいは許諾済みの著作物を活用する方法で著作権等侵害のリスクを回避する方法もある。例えば、Adobeが提供する「Adobe Firefly」は、オープンライセンス等、著作権の問題の無い画像を学習段階で利用しており、著作権侵害の心配なく生成した画像の商用利用が可能としている。




第2節 AIに関する各国の対応

　こうした生成AIをはじめとするAIの急速な普及のなかで生じた倫理的・社会的な課題に対処するためには、国内のみならず、諸外国と協調した取組が必要である。

1 国際的な議論の動向

1 広島AIプロセス
　AIについての倫理的・社会的課題に対する議論は2015年頃から活発化しており、我が国は、早期からG7/G20や経済協力開発機構（以下「OECD」という。）等における議論を先導し、AI原則の策定に重要な役割を果たしてきた。2016年4月に高松で開催されたG7情報通信大臣会合において、日本からAIの開発原則に関する議論が提案され、その後OECDで合意されたAI原則が2019年5月に公開されたことを受けて、同年6月のG20首脳会合にて、「G20 AI原則」が合意された。2019～2020年には、AI原則については国際的なコンセンサスが形成されつつあり、同原則を社会に実装するための具体的な制度や規律の策定に関する議論に移行している。更には、2022年の生成AIの急速な普及により、G7等の国際協調の場においても、また各国においても、AIガバナンスの議論が活発化している。
　2023年4月、群馬県高崎市でG7群馬高崎デジタル・技術大臣会合が開催され、生成AIの急速な普及と進展を背景に、「責任あるAIとAIガバナンスの推進」などについて議論が交わされた。同会合では、G7のメンバー間で異なる、AIガバナンスの枠組み間の相互運用性の重要性が確認され、「責任あるAIとAIガバナンスの推進」、「安全で強靱性のあるデジタルインフラ」、「自由でオープンなインターネットの維持・推進」等の6つのテーマからなる閣僚宣言が取りまとめられた。同宣言はその後、5月に広島で開催された主要7か国首脳会議（G7広島サミット）における議論に反映され、当該サミットの首脳コミュニケ（宣言）において、生成AIに関する議論のための広島AIプロセスの創設が指示された。具体的には、OECDやGPAI（後述）等の関係機関と協力し、G7の作業部会にて調査・検討を進めることとなった。
　2023年9月には、7月～8月にOECDが起草したレポートや、生成AI等を含む高度なAIシステムの開発に関して議論すべく閣僚級会合が開催され、透明性、偽情報、知的財産権、プライバシーと個人情報保護等が優先課題であることが確認された。その後10月30日に「広島AIプロセスに関するG7首脳声明」が発出され、まずは高度なAIシステムの開発者を対象とした国際指針と行動規範が公表された。更に同年12月には、AIに関するプロジェクトベースの協力を含む広島AIプロセス包括的政策枠組みや、広島AIプロセスを前進させるための作業計画が発表されている。

2 OECD／GPAI／UNESCOの動き

ア　OECD
　OECD、GPAI、UNESCO等、多くの国際機関もグローバルな観点からAIガバナンス制度の検討を進めている。2019年5月にOECDのAI原則が公開されて以降、各種OECDレポートの発表やプロジェクトの推進等、G7との連携の下、積極的な活動が行われている。また、OECD、GPAI、UNESCOの3機関は、2023年9月に「生成AI時代の信頼に関するグローバルチャレンジ（Global Challenge to Build Trust in the Age of Generative AI）」を発表し、G7の包括枠組みを踏まえ、偽情報やディープフェイク等による社会的リスクに対し、イノベーティブな解決策を進めるグローバルな連携プロジェクトを推進している。
　2024年5月に開催されたOECD閣僚理事会では、生成AIに関するサイドイベント「安全、安心で信頼できるAIに向けて：包摂的なグローバルAIガバナンスの促進」において、岸田総理大臣から49か国・地域の参加を得て広島AIプロセスの精神に賛同する国々の自発的な枠組みである「広島AIプロセス　フレンズグループ」を立ち上げることを発表した。

イ　GPAI
　「AIに関するグローバルパートナーシップ（Global Partnership on AI）」（以下「GPAI」という。）は、2020年、人間中心の考え方に立ち、「責任あるAI」の開発・利用を実現するために、OECDとG7の共同声明により創設された。同組織は、OECDが事務局を務め、価値観を共有する政府、国際機関、産業界、有識者等からなる官民国際連携組織で、現在29か国が参加している。GPAIには、「責任あるAI」、「データ・ガバナンス」、「仕事の未来」、「イノベーションと商業化」という4つの研究部会が設置されており、専門家による議論と実践的な調査が実施されている。GPAIの年次サミットである「GPAIサミット2023」においては、新たなGPAI専門家支援センターである、GPAI東京専門家支援センターの立ち上げが承認された。同センターでは、生成AIに関する調査・分析等のプロジェクトを先行的に実施する予定となっている。

ウ　UNESCO
　国連教育科学文化機関（UNESCO）も、2021年にAIの倫理に関する勧告「UNESCO Recommendation on the Ethics of Artificial Intelligence」を採択し、各国における取組を支援している。2023年9月には、教育・研究に関する初の生成AIのグローバルガイダンスである「教育・研究分野における生成AIのガイダンス（Guidance for generative AI in education and research）」を公表し、生成AIの定義や説明、倫理的及び政策的な論点と教育分野への示唆、規制の検討に必要なステップ、カリキュラムデザインや学習等について紹介している。ほとんどの生成AIが主として大人向けに設計されていることから、教育現場での使用は13歳以上に制限すべきと提案し、各国政府には、データのプライバシー保護を含む適切な規制や教員研修等を求めている。


3 AI安全性サミット
2023年5月、OpenAIは、今後10年以内に人間の専門家のスキルレベルを超えるAIシステムが実現する可能性があると発表した。同社はこれを「フロンティアAI（Frontier AI）」と命名し、核エネルギーや合成生物学等の人類の存在上のリスクに鑑みて、事後的対応ではなく国際的な規制を検討すべきとした。これを受けてスナク英国首相は、2023年11月1日～2日に英国ブレッチリーにて、「AI安全性サミット」を開催した。従来の人権や公平性といった「AI倫理」を超えて、AIによる「深刻且つ破滅的な危害」の防止を視野に入れた「AIの安全性」について議論されたことが特徴的である。
　本サミットの成果文書として「ブレッチリー宣言」が採択された。また、英国はAIセーフティ・インスティテュートを設置することについても決定した。
　2024年5月21日～22日には、韓国・英国共催により「AIソウル・サミット」が開催された（21日の首脳セッションはオンライン開催、22日の閣僚セッションはソウルで対面開催）。AI安全性の議論を深めるとともに、AI開発におけるイノベーション促進及びAIの恩恵の公平な享受について議論が行われ、首脳級の成果文書として「安全、革新的で包摂的なAIのためのソウル宣言」及び付録「AI安全性の科学に関する国際協力に向けたソウル意図表明」、閣僚級の成果文書として「安全、革新的で包摂的なAIの発展のためのソウル閣僚声明」が採択された。今後、2025年2月にフランスにて次回会合が開催される予定となっている。


4 国際連合の動向
　前項のとおり、フロンティアAIに対する国際的なガバナンス体制への関心の高まりを受けて、2023年7月の国連安全保障理事会においては、英国主導でAIに関する議論が行われた。グテーレス国連事務総長は同年10月に、事務総長の諮問機関として、AIハイレベル諮問機関を立ち上げ、日本人の構成員も参加している。また、2024年3月21日、国連総会において、日本も共同提案国である、「持続可能な開発のための安全、安心で信頼できるAIシステムに係る機会確保に関する決議」＊9をコンセンサスで採択し、同決議案は、安全、安心で信頼できるAIに関する初めての国連総会決議となった。同決議案は「持続可能な開発のための2030アジェンダ」の達成に向けた進捗を加速し、デジタルディバイドを解消するため、安全、安心で信頼できるAIを促進しており、加盟国に対し、安全、安心で信頼できるAIに関連する規制・ガバナンスアプローチの策定・支持を推奨している。さらに、加盟国及びステークホルダーに対し、AI設計・開発中のリスク特定・評価・軽減のためのイノベーション促進や、データ保全のためのリスク管理メカニズムの策定・実施・公表等の手段を通じて、AIシステムが世界の課題に対応できるための環境を整備するよう推奨している。また、AIシステムのライフサイクルを通じて、人権及び基本的自由が尊重され、保護され、促進されるべきことを強調している。
　同決議案は、AIの国際ルールづくりに向け、広島AIプロセスをはじめ、G7やG20、OECD等で進めてきた議論を反映したものであり、国連総会決議には国際法上の拘束力はないものの、コンセンサスで加盟国が採択したということから、国際社会の総意としての政治的な重みを持つものである。


2 各国における法規制・ガイドライン等の整備動向

　現在、AIに関する法制度や国際標準に関する議論が世界各国で活発に行われており、2023年はEUのAI法の欧州議会での採択、米国のAIの安全性に係る大統領令、日本のAI関連事業者向けのガイドライン案の公表など、AI政策にとっては大きな節目となる年となった。それぞれの国、地域におけるAIに関する規制の動きを見ると、生成AIに対する急速な関心の高まりを受けて、各国・地域ではそれまで検討してきたガバナンス制度の見直しが求められている。進化が速い技術に関する規制の整備においては、各国政府が主導しつつも、AI事業者側の自主的な取組も必要であり、官民両輪で進められているところである。

1 欧州連合（EU）
　域内発のビッグテック企業が無い欧州は、他の地域に先駆けて最も厳しい規制を志向し、2020年からAIの規制に関する議論を続けてきた。2024年5月21日には、欧州市場でAIシステムを開発・提供・利用する事業者を対象とする、法的拘束力を持つ世界初の包括的なAI規制法と位置付けられるAI法（AI Act）（以下「AI法」という。）が成立した。AIの規制に関する包括的な法律の成立は主要国・地域で初めてとされており、今後段階的に適用が開始され、2026年頃には本格的に適用される見込みである。
　AI法は、リスクに応じて規制内容を変える「リスクベースアプローチ」という方針に基づいている。規制対象を、①許容できないリスク、②高いリスク、③限定的なリスク、④最小限のリスク、という4段階のリスクレベルのAIアプリケーション及びシステムに分類し、それぞれに対して異なる規制を課すこととしており、上記の規制に違反した事業者には、最も重い違反の場合、最高で3,500万ユーロ（約56億円）の罰金、あるいは年間売上高の7％の制裁金が科される可能性がある。

2 米国
　ビッグテック企業を多く保有する米国は、自国の企業保護に力を入れ、政府による規制よりも民間での自主的な対応を優先し、企業の取組に任せつつ必要の場合に政府が規制をかけるという立場をとってきた。民間側の取組として2023年7月、AI開発で先行する7社（Google、Meta PlatformsやOpenAI等）がAIの安全な開発のための自主的な取組を約束したこと、更に9月には新たな8社（IBM、Adobe、NVIDIA等）がそれに合意したことを米国政府が発表した。各社は、自主的なコミットメント（Voluntary Commitments）として、安全性、セキュリティ、信頼性の3つの観点から原則を掲げている。
　ホワイトハウスは、強制力のある規制が導入されるまで、各社が上記の取組を続けるとしていたが、その3か月後となる2023年10月30日、バイデン大統領は、「安全・安心・信頼できるAIの開発と利用に関する大統領令（Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence）」を発表した。対象とするAIの問題については、従来の倫理的観点から、安全保障問題に範囲を拡充しており、対象となる事業者はビッグテック企業に限らず、バイオテクノロジー企業等、国家の安全保障や経済に影響を及ぼす可能性のあるサービスや製品を取り扱う企業も含まれる。その内容については、AIに関する新たな安全性評価、公平性と公民権に関するガイダンス、またAIが労働市場に与える影響に関する調査等を義務付けるものであり、AIの安全性とセキュリティのための新しい基準、米国民のプライバシー保護、公平性と公民権の推進等をその主要な構成要素としている。
　大統領令の発表に引き続き、同年11月には、ハリス副大統領が、先述の英国AI安全性サミットにて「安全で責任あるAI利用の新イニシアチブ（New U.S. Initiatives to Advance the Safe and Responsible Use of Artificial Intelligence）」を発表し、その中で、大統領令の内容を具体化するべく、「米国AI安全研究所（AI Safety Institute）」（以下「US AISI」という。）を設置するとした。US AISIは、国立標準技術研究所（National Institute of Standards and Technology：NIST）内に設置され、危険な機能を評価及び軽減するためのガイドライン、ツール、ベンチマーク、ベスト プラクティスを作成し、AIリスクを特定して軽減するためのレッドチームを含む評価を実施する。また、人間が作成したコンテンツの認証、AIが生成したコンテンツの電子透かし、有害なアルゴリズムによる差別の特定と軽減や透明性の確保、プライバシー保護の導入等に係る技術的なガイダンスを開発する予定である。英国のAI安全研究所を含む国際的な同業機関との情報共有や研究協力、更には市民社会、学界、産業界の外部専門家との提携も可能となる。
　一方、連邦議会でも連邦レベルでのAI規制に関する法案が議論されている。2023年6月には、上院が、AIの急速な進歩に連邦議会が対応するための包括的な枠組みである「安全なイノベーション枠組み（SAFE Innovation Framework）」を提唱し、同年12月までに産業界の代表や有識者を招いたテーマ別のフォーラムを9回にわたって開催した。他方の下院は、2024年2月、AIに関する超党派のタスクフォースを設立すると発表し、AI政策の指針となる原則や政策提言を含む包括的な報告書を作成する予定となっている。上下両院では、選挙等の個別分野でのAI利用を規制する法案が複数提出されているものの、未だ議会を通過したものは無い。2024年秋に大統領選挙を控える米国では、生成AIの普及に伴うディープフェイクによる情報操作等の課題に直面し、AIの規制に関する議論が益々活発化するものと予想される。

3 英国
　英国は米国と中国に次いでAI研究が盛んな国とされており、AI分野への民間投資額においても、シンガポールの躍進により2023年に初めて4位に転落したものの、2019年以来、米国・中国に次いで世界3位を保ってきた。現スナク政権は、法的拘束力のあるAI規制には消極的で、安全に配慮しながらAIシステムの開発を促し、経済成長に繋げたいとする考えから、当面はEUのAI法のような厳格な規制を新たに整備せず、既存の枠組みで柔軟に対処する方針を表明してきた。同方針を踏まえ、英国政府が2023年3月に公表した政策文書「プロイノベーティブな規制手法（A pro-innovation approach to AI regulation）」が、同国のAI規制の基本的な枠組みに位置付けられている。同文書では、セキュリティ、透明性、公平性、説明責任、争議可能性の観点から5つの原則が掲げられており、AIガバナンスに取り組むに当たっては、「イノベーション促進型の、柔軟で法規制に縛られない、比例的で信頼できる、順応性があり、明確で且つ協力的な（proinnovation, flexible, non-statutory, proportionate, trustworthy, adaptable, clear and collaborative）」アプローチをとるとしている。当面は既存の法規制の下、各政府機関の連携により、産業界に対して上記原則の実装を促しつつ、将来的には、原則について何らかの義務化を図る可能性があるとしている。
　また、2023年11月27日、英国国家サイバーセキュリティセンター（National Cyber Security Centre：NCSC）と米国サイバーセキュリティ・インフラストラクチャー安全保障庁（Cybersecurity and Infrastructure Security Agency：CISA）が中心となり、日本を含む18か国が共同で、AIシステムのセキュリティガイドラインである「セキュアAIシステム開発ガイドライン（Guidelines for secure AI system development）」＊28を公表した。同ガイドラインでは、AIの設計、開発、導入、運用とメンテナンスの各段階において、取り組むべき事項を取りまとめている。

4 日本
　日本は、民主主義や基本的人権等の観点からは欧米と同様の立場である一方、文化や社会規範の差異により、AIに対する社会認識という点では、欧米とは異なる文化圏にある。これにより、AIガバナンスの方向性として、欧州が法的拘束力の強いハードローを志向しているのに対し、日本は現時点では、AIガバナンスに関する横断的な法規制によるアプローチではなく、民間事業者の自主的な取組を重んじるソフトローアプローチを志向しており、総務省と経済産業省を中心に取組が行われてきたところである。総務省のAIネットワーク社会推進会議による「AI開発ガイドライン」が2017年に、「AI利活用ガイドライン」が2019年に公表され、また同年3月に内閣府の統合イノベーション戦略推進会議が決定した、「人間中心のAI社会原則」を基にしたガイドラインが策定された。続いて2021年7月に経済産業省が公表した「AI原則実践のためのガバナンス・ガイドライン」（2022年1月に改訂）では、AI事業者が実施すべき行動目標が実践例と共に示されている。同ガイドラインは、AIを開発・運用する事業者が参考にし得るよう、環境・リスク分析やシステムデザイン、運用等の項目毎にまとめられている。
　2023年5月、政府は「AI戦略会議」を設置し、AIのリスクへの対応、AIの最適な利用に向けた取組、AIの開発力強化に向けた方策等、様々なテーマで議論を行い、「AIに関する暫定的な論点整理」を公表すると共に、各省庁のガイドラインの統合に向けた作業を進めることとされた。同年9月には、同会議にて生成AIに対するガバナンスも含めて統合された「新AI事業者ガイドライン スケルトン（案）」が示され、そして12月、政府は「AI事業者ガイドライン案」を公表した。同案では、人権への配慮や偽情報対策を求め、安全性やプライバシー保護等の10原則を掲げ、人間の意思決定や認知・感情を不当に操作するものは開発させないとしているが、欧米のような一定の法的拘束力を持つものではない。同案はその後、一般からの意見の公募を経て、2024年4月19日に「AI事業者ガイドライン（第1.0版）」として公表された。
　また、2023年12月のAI戦略会議において、岸田総理大臣は、AIの安全性に対する国際的な関心の高まりを踏まえ、AIの安全性の評価手法の検討等を行う機関として、米国や英国と同様に、日本にも「AIセーフティ・インスティテュート（AI Safety Institute）」（以下「AISI」という。）を設立すると発表し、2024年2月14日、経済産業省所管の情報処理推進機構（Informationtechnology Promotion Agency：IPA）に設置された。AISIは、英国・米国等の同様の機関とも連携しつつ、AIの開発・提供・利用の安全性向上に資する基準・ガイダンス等の検討、AIの安全性評価方法等の調査、AIの安全性に関する技術・事例の調査などを行っていくこととしている。




第3節　その他デジタルテクノロジーに関する議論の動向

1 メタバース、ロボティクス、自動運転に関する議論の動向

1 メタバース
　総務省の「Web3時代に向けたメタバース等の利活用に関する研究会」が2023年7月に取りまとめた報告書においては、メタバースに関する課題は、「メタバース空間内に係る課題」と「メタバース空間外と関連する課題」の2つに大別されている。
　メタバース空間内に係る課題については、①アバターに係る課題、②プラットフォーム間の相互運用性、③メタバース構築時・利活用時に係る課題、④データの取得・利用に係る課題が、メタバース空間外と関連する課題については、⑤ユーザーインターフェース（UI）/ユーザー体験（UX）に係る課題、⑥メタバースの動向/社会的な影響が挙げられた。同研究会ではこれらの課題について検討し、①～④の課題に対する取組の方向性としてメタバースの理念に関する国際的な共通認識の形成、相互運用性確保に向けた取組（標準化等）及びメタバース関連サービス提供者向けガイドライン（仮）の策定を、⑤～⑥の課題に対する取組の方向性としては市場、技術、ユーザー動向の継続的フォローアップ及びメタバースとUI/UXの関係等についての調査研究が挙げられる旨を整理した。また、2023年10月からは、同研究会の報告書において継続的なフォローアップが必要とされたものについての検討等を行う「安心・安全なメタバースの実現に関する研究会」を開催している。2023年4月の「G7群馬高崎デジタル・技術大臣会合」や同年5月の「G7広島サミット」において確認された民主的な価値に基づくメタバースの発展を念頭に、ユーザーにとってより安心・安全なメタバースを実現することを目的として、①メタバースの自主・自律的な発展に関する原則（オープン性・イノベーション、多様性・包摂性、リテラシー、コミュニティ）及び②メタバースの信頼性向上に関する原則（透明性・説明性、アカウンタビリティ、プライバシー、セキュリティ）からなる「メタバースの原則（1次案）」の検討等が行われてきたところである（本研究会については、本年夏頃に報告書を取りまとめ予定）。
　国際機関においてもメタバース等の没入型技術に関する検討が行われており、例えばOECDでは、2022年12月にGlobal Forum on Technology（GFTech）＊3の設置を公表し、没入型技術等についてフォーカスグループ（FG）を設置して議論をしている。没入型技術に関するFGでの議論は2023年12月から開始しており、2024年秋頃に報告書を取りまとめる予定となっている。また、総務省では、2023年10月に国連が主催した「インターネット・ガバナンス・フォーラム（IGF）京都」において、「民主的価値に基づくメタバースの実現」をテーマとしたセッションをOECDと共同開催するなど、国際的な議論に貢献する取組を進めている。

2 ロボティクス
　ロボティクスは従来我が国が強みを有する技術であり、特に産業用ロボットについては世界市場シェアの46％を占めている。また、労働人口減少が続く我が国においては、ロボティクス活用による生産性の向上、不足する労働力への対応、新たな産業創出等の期待も大きい。我が国では2015年度に「ロボット新戦略」を策定し、これまで30以上の官民連携による技術開発プロジェクトを実施してきており、ロボット自体やそれを支える個々の技術は進化してきている一方、ロボット導入現場のニーズとの間のギャップにより社会実装が進んでいないという実態もある。こうした状況を受け、国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）は2023年4月、ロボット技術戦略の策定およびプロジェクトの早期開始に向けて、社会課題の解決につながるロボット活用を推進するための方向性を大局的に整理・検討した「ロボット分野における研究開発と社会実装の大局的なアクションプラン」を公表した。アクションプランにおいては、ロボット活用が期待される8分野（ものづくり、食品製造、施設管理、小売・飲食、物流倉庫、農業、インフラ維持管理、建築）を取り上げ、あるべき姿の実現に向けて、2030年を目安に短期で求められる施策を「社会実装加速に向けたアクションプラン」、2035年に向けて中長期でのインパクト創出を見据えた施策を「次世代技術基盤構築に向けたアクションプラン」として取りまとめている。今後は、ロボットアクションプランとして抽出された取り組むべき技術開発と環境整備のアクションをもとに、将来の国家プロジェクト化や社会実装に向けた検討を進めていくこととしている。

3 自動運転技術
　自動運転技術の活用は、人口減少、高齢化等が進む地域の足を担う公共交通や物流の維持に寄与することが期待されており、社会利用拡大に向けた取組が求められている。政府は、「デジタル田園都市国家構想総合戦略（2023改訂版）」において、自動運転による地域交通を推進する観点から、関係府省庁が連携し、地域限定型の無人自動運転移動サービスを2025年度目途に50か所程度、2027年度までに100か所以上で実現する目標を掲げている。また、「デジタルライフライン全国総合整備計画」（経済産業省）においては、アーリーハーベストプロジェクトの1つに自動運転サービス支援道の設定が挙げられており、2024年度に新東名高速道路の一部区間等において100km以上の自動運転車優先レーンを設定し、自動運転トラックの運行の実現を目指すほか、2025年度までに全国50箇所、2027年度までに全国100箇所で自動運転車による移動サービス提供が実施できるようにすることを目指すとされている。この計画の実現に向け、警察庁、総務省、国土交通省等関係省庁が連携して取組が行われているところである。


2 サイバーセキュリティの確保に関する議論の動向
　デジタルテクノロジーを国民一人ひとりが安心して活用していくためには、サイバーセキュリティの確保も重要となる。近年、国際情勢の複雑化により、我が国を含む各国において政府機関等を狙ったサイバー攻撃が多く発生している状況にあることに加え、生成AI等のテクノロジーの登場により、利便性が増す一方で、それらの悪用によるリスクの拡大も指摘されている。従来、サイバーセキュリティは主にシステムの可用性や機密性を確保する、つまり、システムが停止しないようにすることや、データの窃取や漏洩を防ぐことに焦点が当てられ、ビジネスの連続性や利便性を確保してきた。これとともに、近年では情報の改ざん、偽・誤情報の拡散など、情報の中身の完全性、信頼性に関わる様々なリスクについても顕在化している。偽情報やディープフェイクの拡散、情報の改ざんや流出は、社会の信頼を揺るがし、社会の安定性や国家の安全保障にも影響を及ぼすだけでなく、政治的なプロセスや意思決定において深刻な影響を及ぼし、民主主義の健全性にとっても大きな脅威となる可能性がある。
　国家安全保障戦略（2022年12月）において「民間の重要インフラ等への国境を越えたサイバー攻撃、偽情報の拡散等を通じた情報戦等が恒常的に生起し、有事と平時の境目はますます曖昧になってきている」 と指摘するように、サイバー空間を巡る脅威はますます深刻化しており、いわば「常時有事」の状況となっているとも言える。こうした状況を踏まえ、さらなる情報通信ネットワークの安全性・信頼性の確保、サイバー攻撃への自律的な対処能力の向上、偽・誤情報への対応、国際連携の推進、普及啓発の推進に向けた取組が進められているところである。




第5章　デジタルテクノロジーの浸透



第1節 国民・企業における利用状況

1 生成AI 

1 国民向けアンケート
　国内外で議論を巻き起こしつつも、利用者の拡大を続けてきた生成AIのサービスは、国民生活にどの程度浸透しているか。総務省は、日本、米国、中国、ドイツ、英国の国民を対象に、生成AIを含む“デジタルテクノロジー”の利用状況等のアンケート調査を実施した。これによると、生成AIを“使っている”（「過去使ったことがある」も含む）と回答した割合は日本で9.1％であり、他国と比べて低かった。
　使っていない理由については、各国とも「使い方がわからない」、「自分の生活には必要ない」との回答が多く、「情報漏洩、安全性、セキュリティに不安がある」との回答の割合は低かった。
　一方、今後の暮らしや娯楽における生成AIの活用意向について聞いてみると、日本では「既に利用している」と回答した割合は低いものの、「ぜひ利用してみたい」「条件によっては利用を検討する」と回答した割合は6～7割程度あり、潜在的なニーズがあることがうかがえた。

2 企業向けアンケート
　次に、各国の企業を対象に、業務における生成AIの活用状況を尋ねた。生成AIの活用方針が定まっているかどうかを尋ねたところ、日本で“活用する方針を定めている”（「積極的に活用する方針である」、「活用する領域を限定して利用する方針である」の合計）と回答した割合は42.7％であり、約8割以上で“活用する方針を定めている”と回答した米国、ドイツ、中国と比較するとその割合は約半数であった。
　次に、生成AIの活用が想定される業務ごとに活用状況を尋ねたところ、例えば、「メールや議事録、資料作成等の補助」に生成AIを使用していると回答した割合は、日本で46.8％（“業務で使用中”と回答した割合）であり、他国と比較するとその割合は低い。“トライアル中”までを含めると、米国、ドイツ、中国の企業は90％程度が使用しており、海外では、顧客対応等を含む多くの領域で積極的な利活用が始まっている一方で、日本企業は社内向け業務から慎重な導入が進められていることがわかった。
　生成AI活用による効果・影響について尋ねたところ、約75％が“業務効率化や人員不足の解消につながると思う”（「そう思う」と「どちらかというとそう思う」の合計）と回答していた。一方、“社内情報の漏洩などのセキュリティリスクが拡大すると思う”、“著作権等の権利を侵害する可能性があると思う”と回答した企業も約7割であり、生成AIのリスクを懸念していることがうかがえた。

 2 メタバース 

1 国民向けアンケート
　メタバースの利用経験について聞いたところ、“使っている”（過去使ったことがあるも含む）と回答した割合は日本は6.1％と低かった。
　活用シーンごとの利用状況・意向を聞いてみると、「仮想空間上でのユーザー同士のコミュニケーション」を「既に利用している」と回答した割合は日本で2.9％と、約15～30％がすでに利用している他国と比べると低い結果となったものの、今後の利用に前向き（“ぜひ利用してみたい”、“条件によっては利用を検討する”）な回答と合わせると52.9％と、潜在的な利用ニーズがあることがうかがえた。

2 企業向けアンケート
各国の企業に、メタバース・デジタルツインの業務での活用について、「商品開発」、「製造」、「物流」等の業務別に導入の検討状況を尋ねたところ、「有用だと考えており、既に導入済み」と回答した割合はいずれの業務でも日本では10％未満となっており、約45～60％が導入済みと回答した米国に比べて低くとどまっていた。

3 ロボティクス
　各国の国民の暮らしや娯楽におけるロボット利用に関する意識を調査するため、ロボットの利用が想定される6つの場面ごとに利用意向を尋ねたところ、“家事（掃除、洗濯、料理など）をロボットが代行する”ことについて前向き（既に利用している、ぜひ利用してみたい、条件によっては利用を検討する）な回答が日本で75.3%と高く出た。この割合は米国、ドイツ、英国と同程度である。
　また、米国、ドイツ、英国では、6つの利用場面いずれに対しても「利用したくない」と回答した割合が約30％と比較的大きくなっていた。

4 自動運転
　完全自動運転車（ドライバー不在の運転が可能）の利用意向を尋ねたところ、日本では、設定した5つの場面いずれにおいても、「利用意向がある」（ぜひ利用してみたい、条件によっては利用を検討する）と回答した割合が約6割程度となっていた。一方、「利用したくない」と回答した割合は日本で約2割程度であったのに対し、米国、ドイツ、英国では約3割程度と、利用に後ろ向きな傾向がみられた。




第2節 活用の現状・新たな潮流

　前節でみたとおり、生成AIをはじめとするデジタルテクノロジーは、現時点では国内の利用が進んでいないものの、潜在的な利用意向が存在し、将来サービス・コンテンツとともに活用が進む可能性を秘めている。本節では、企業等における生成AI活用促進に資する先進事例と、今後社会課題解決等が期待されるデジタルテクノロジーの活用事例等を概観する。

1 業務変革を担う生成AI
　本項では、企業や公共団体で導入・活用が始まっている生成AIについて、導入・活用の実態とリスクに対する考え方、健全な活用促進に向けた取組の工夫等についてとりまとめた。

1 企業・公共団体等における生成AI導入動向
　生成AIの導入を積極的に推進する企業等においては、AIのリスクや社会的影響を評価・検証しながら、活用を促進するための体制構築やルール整備等の取組を進めている。

ア　NTTデータ
　NTTデータは、2019年5月に「NTTデータグループAI指針」を策定、同社のAIガバナンスの在り方を検討するため2021年4月に社外の有識者からなる「AIアドバイザリーボード」を設置するなど、従来から公平かつ健全なAI活用による価値創造と持続的な社会の発展に向けた活動を実施してきたが、さらに、ビジネスに影響するAIの不適切な利用による事業リスクに適切に対処し、お客さまに安全なAIシステムの提供を実現するための組織として、AIガバナンス室を2023年4月に設置した。同年7月からはNTTデータの国内事業でAIやデータ活用が関わる案件全てを対象に、チェックリストを使いリスク管理をする運用を始めた。

イ　横須賀市
　横須賀市は、庁内における取組として、2023年4月のChatGPTの全庁での活用実証から始め、職員の活用促進や正しい利用方法の発信のための「ChatGPT通信」創刊、職員向けの独自研修プログラム、職員を対象としたChatGPT活用コンテスト、外部からのアドバイスを受ける目的での「AI戦略アドバイザー」の設置等の取組を行っている。また、庁内で培った知見やノウハウを他の自治体にも共有を行っており、2023年8月より取組内容に関する問合せに回答する他自治体向けの問合せボットの運用を開始、さらに同月、先行して生成AIを活用する自治体のノウハウや試行錯誤の過程を発信するポータルサイト「自治体AI活用マガジン」を立ち上げた。全国の自治体や企業向けに2日間にわたる研修プログラム「横須賀生成AI合宿」の開催も行った。
　さらに、これらの知見を活かし、福祉の相談窓口で相談対応を行う職員向けの「AI相談パートナー」なども導入している。

2 各領域・業界における活用動向

ア　コンテンツ制作等における活用（サイバーエージェント）
　メディアやゲーム、音楽などのコンテンツ制作分野においては、コンテンツそのものの制作や制作における補助として生成AIを利用することで、労働力不足の中で、クリエイターがより効率的にコンテンツを作成することが可能となる。
　サイバーエージェントでは、2023年5月に、AIを活用した広告クリエイティブ制作を実現する自社開発の「極予測AI」に、ChatGPTを活用したキャッチコピー文案自動生成機能を実装した。これにより、広告画像の内容を考慮しながら、従来よりも詳細なターゲットに合わせて広告コピーを作り分けることができるようになった。また、2023年12月にはAIを活用した商品画像自動生成機能を開発し、あらゆるシチュエーションと商品画像の組合せを大量に自動生成することが可能になった。さらに生成した商品画像と効果予測AIを活用し、予測を行いながらより効果の高い商品画像の提供を実現するとしている。

イ　顧客接点における活用（アフラック生命保険）
　顧客サービス分野においては、利便性向上のための利用者向けサポートと、利用者に対峙するスタッフの業務効率向上のための支援や教育、サービス自体の健全な利用のために不正検知を行うといった活用方法がある。顧客接点における満足度向上の側面や、さらに応対する個人の知識やセンスを問わず一定の品質を保てるようになることが見込まれている。特に離職率が高く人手不足になりがちなコンタクトセンター等の分野でオペレーターに適切な知識を伝え業務の後方支援を行うことによる労働力不足解消の可能性を秘めている。
　例えば、アフラック生命保険では、保険代理店向けサービスとして、AIのアバターを相手とするロールプレイング研修「募集人教育AI」を開発した。営業担当者が保険セールスの会話の中で挙げるべきキーワードを盛り込んでいるかどうかなどを、音声認識をはじめとする技術を用いて分析して評価する仕組みであり、将来的には、実際の顧客の情報を取り込んで、営業活動を疑似体験できるところまで機能の発展を見込む。

ウ　情報サービス（NTTデータ）
　ソフトウェア開発等を行う情報サービス分野において、生成AIは要件定義、仕様生成、プログラミング、テストなどのあらゆる工程での活用が見込まれている。生成AIによる生産性向上により、エンジニアの需要が高まる中で人手不足解消の手助けとなる可能性を秘めている。特に、SIerにおいては、COBOL資産のモダナイゼーションへの活用も目論んでいる。
　NTTデータでは、要件定義からテスト工程までシステム開発の全フェーズで生成AIの適用の推進を行っている。海外を中心にPoCだけでなく商用利用での適用実績があり、製造工程において7割の合理化によって工期を短縮した例や、生産性を約3倍向上させた例もある。2023年10月には日本におけるマイグレーションのPoCを始めている。製造工程やテスト工程における利用が現時点でメインとなっており、製造工程においては新規ソースコードの生成や古いプログラム言語を新しいプログラム言語に書き換えるモダナイゼーションに活用する。テスト工程においては過去の設計書や試験目標等のデータを生成AIに読み込ませ、テスト項目を自動抽出できるようにするとしている。

エ　建設分野における活用（大林組）
　建設分野においては、デザイン案の短時間での作成や、設計の際、測量データ、設計図書、仕様書の過去データを参照する場面などで活用が見込まれている。膨大な時間外労働、職人の高齢化による大量離職、資材価格の高騰などにより業界全体が圧迫されている中、書類作成などの効率化、ベテランの経験の活用、公開情報と社内の専門的な知見の結びつけにおいて効果が期待されている。
　大林組は、2022年3月に建築設計の初期段階におけるスケッチや3Dモデルからさまざまな建物の外観デザインを提案できるAI技術「AiCorb（アイコルブ）」を米SRI Internationalと共同で開発したと発表し、2023年7月より社内運用を開始した（2024年5月末時点で3万枚以上の画像を生成）。AiCorbは２つのAIで構成され、社内運用を開始している画像生成AIでは、手描きのスケッチとデザインを指示する文章を基に、様々なファサード（建物の正面外観）のデザイン案を短時間で複数案出力することが可能である。もう一つは、生成したデザインの3次元（3D）モデル化を補助する3次元変換AIである（現在Revitモデルに対応するプラグインを開発済）。将来的には、3次元化されたデータを活用して各種性能評価をおこなうことで、設計者や発注者の判断や合意形成をサポートするツールを目指している。

オ　材料分野における活用（Preferred Networks、ENEOS）
　材料開発の分野においては、AIの機械学習や統計手法を使用して大量の実験・計算データを解析、モデルを構築し新材料開発につなげるデータ駆動型アプローチ（Materials informatics（マテリアルズ・インフォマティクス））が発展してきた。生成AIについても、敵対的生成ネットワーク（GAN）や変分自己符号化器（VAE）といった生成モデルを活用し、既存の材料データセットを学習し、理論上の新材料を設計することで新しい材料の分子構造や結晶構造を自動的に生成することが可能になるほか、生成AIを使用して実データに基づいた仮想データを生成し、実験データセットを拡張することで、モデル学習の改善につながる。
　2021年7月に、Preferred NetworksとENEOSはPreferred Computational Chemistry（PFCC）を共同で設立し、ディープラーニング（深層学習）を活用した汎用原子レベルシミュレーター（Matlantis（マトランティス））をクラウドサービスとして提供開始した。生成AIを活用した原子シミュレーションによって、原子レベルでの有望な材料の特性把握や新材料開発や材料探索を支援する。従来のシミュレーションと比べて精度を保ったまま10万倍から数千万倍高速化し、高性能なコンピュータを用いて数時間～数か月かかった原子レベルの物理シミュレーションを、数秒単位で行うことが可能となったほか、55種類の元素をサポートし未知の分子や結晶など未知の材料に対してもシミュレーションできる汎用性を兼ね備え、国内外で80以上の大学・企業に利用されている（2024年1月時点）。


3 公的領域における活用

ア　教育（ベネッセ等）
　教育分野においては、学習者自身が生成AIと会話を行うことで個別にカスタマイズされた教材で自律的な学習、学習者の質問に回答するなどの学習支援、教材やテストの作成補助などの教師向けの支援等への活用が見込まれている。実際に学校に配置されている教師の数が、各都道府県・指定都市等の教育委員会において学校に配置することとしている教師の数を満たしておらず欠員が生じる状態である深刻な「教師不足」が続くこの分野において、生成AI活用を行うことで学習者にはいつでも気兼ねなく質問ができる環境や自律的な教育支援、教師の教材作成における稼働削減につながる可能性を秘めている。
　文部科学省では、2023年7月に「初等中等教育段階における生成AIの利用に関する暫定的なガイドライン」を公表し、学校現場が生成AIの活用の適否を判断する際の参考となるよう一定の考え方をとりまとめている。また、同年、本ガイドラインに基づき、生成AIへの懸念に対して十分な対策を講じられる37自治体52校を生成AIパイロット校として指定し、学校現場における利用に関する成果・課題の検証を進めている。
　他にも、ベネッセコーポレーションは、「自由研究お助けAI」、「AIしまじろう」、「チャレンジAI学習コーチ」等自社の教育サービスへの展開を行っている。2024年3月に提供開始された「チャレンジAI学習コーチ」は、「進研ゼミ」の学習や学校の宿題に取り組む中での疑問点をいつでもわかるまで質問できる、生成AIを活用した小・中学生向けのサービスである。教育における生成AIの活用における課題の一つとされる「答えを直接聞いてしまう」との懸念に対し、「チャレンジAI学習コーチ」は、問題の答えを直接教えるのではなく、子どもたちの疑問に寄り添い、AIキャラクターと対話を通じて考え方や視点を広げるサポートをし、自ら答えにたどり着けるように開発されている。

イ　医療・介護における活用（シーディーアイ）
　医療・介護分野において、生成AIは個々の利用者に合わせたケアプランの最適化や業務報告の自動化、利用者とのコミュニケーションの改善、研修や教育ツール等としての活用が見込まれており、利用者だけではなく職員に必要な専門知識を補う効果や業務効率化が期待される。高齢者人口の増加により需要が増し、生産年齢人口の急減に伴い労働力不足が課題となるこの分野においては、生成AIがより自然な言語で職員の業務上の相談相手となる可能性を秘めている。
　シーディーアイは、2023年6月にAIを活用したケアマネジメント支援ツール「SOIN」とChatGPTとの連携を開始した。ケアマネジャーが既に入力している利用者の属性情報、疾患、身体状態などの情報に基づき、SOINサーバーがChatGPT向けのコマンドプロンプトを自動作成し、ChatGPTはパーソナライズされた支援内容をケアマネジャーに提供する。また、同社は2023年12月に「SOIN AI Chat」をリリースし、高齢者一人ひとりの個別状況を考慮した上で、ケアマネジャーの相談相手となる機能も追加している。

ウ　行政サービスにおける活用（議事録検索）
　行政サービスにおいては、情報収集や政策案の策定などの政策の検討、過去法案の収集や法案策定、（法案審議における）答弁作成などの一連の法制化事務、政策の周知や問合せ対応などの情報提供、様式の作成、チェックや判断、結果の交付などの執行、会議の実施などの事務における活用が見込まれている。例えば、自動処理は、2023年6月に国会議事録検索の出来るChatGPTプラグイン（The Diet Search Plugin）をリリースした。ニュース、トレンド、提案、要望、不満などの文章を元に、その意味に近い国会議事録の議論を出典元情報と共に検索できる。これにより、誰でも簡単に国会の議論を調査、取りまとめを実施することが可能となっている。

エ　経営、バックオフィスにおける活用（エクサウィザーズ）
　バックオフィスにおいては、過去データを参照し経営や人事に活用、法務関連情報との連携を行った契約書修正等において活用が見込まれている。2023年5月、エクサウィザーズは、株主総会や決算説明会における想定問答の作成を支援する「exaBase IRアシスタント powered by ChatGPT」を発表。2023年12月には生成AIを活用した採用業務効率化サービスに参入、最初の取組として、生成AI技術を応用したサービス開発力と、HR Tech領域で蓄積した知見やデータを掛け合わせ、採用領域の業務効率化サービス「exaBase採用アシスタント」のβ版をリリースしている。


2 進化したテクノロジー活用による社会課題解決への期待昨今進化を遂げているメタバース、ロボティクス、自動運転等の技術は、インクルーシブな社会の実現や労働力不足などの解決に寄与する可能性を秘めており、中長期的な未来にはこれらのテクノロジーと生成AIとの掛け合わせで更なる社会課題解決にも活用が期待できる。

1 メタバース
　引きこもりの人や不登校の児童等、外に出ることが難しいという場合においても、誰もがメタバース上でコミュニケーションを取ることが可能である。距離や場所を超えてメタバース上でのコミュニケーションを取ることが社会参加のきっかけとなり、インクルーシブな社会を実現できる可能性が秘められている。
　また、生成AIの発展により、メタバース空間の構築がより容易になったり、キャラクターと自然な会話が可能になったりしている。さらにメタバース空間内に存在するプレイヤーが操作しないキャラクターの開発に必要な要素を、専門知識が無い場合でもテキスト入力のみで自動生成し、メタバース空間上のにぎわいの創出につなげるような生成AIも開発されている。

ア　学習支援（カタリバ、NTTスマートコネクトとNTTデータNJK）
　カタリバは、2021年よりメタバースを活用したオンライン不登校支援プログラムを開始した。官民連携で「room-K」という名称で自治体への導入を行っており、2022年度は埼玉県戸田市や東京都文京区、大阪府大東市など8自治体と連携してメタバース空間で授業を実施した。
　NTTスマートコネクトとNTTデータNJKは教育機関向け3Dメタバースサービス「3D教育メタバース」の提供を開始した。メタバース空間において教室や集会所など実際の教育現場と同様の空間を提供している。トラブルを防ぐためのNGワードフィルターを備えたテキストチャット機能などアバター同士の多様なコミュニケーション空間を提供している。

イ　就労支援（福岡県）
　福岡県は、引きこもりの人や働くことに不安を持つ人を支援しようと、ネット上の仮想空間でアバターを操り、第三者との交流や相談ができる「ふくおかバーチャルさぽーとROOM」を開設している。仕事に就いていない県内在住の16歳以上が利用対象で、悩みを抱える人同士が語り合える談話スペースやスキルアッププログラム、ジョブトレーニングを提供する。2022年度に実証事業としてメタバース上に専用の支援空間を構築、県内2か所で利活用を行い、2023年度からは本格稼働を開始した。

ウ　“メタバース区役所”（東京都江戸川区）
　東京都江戸川区は、自宅や会社などから手続きや相談を行うことができる「来庁不要の区役所」を目指し、電子申請やオンライン化を進めてきた。その一環として、メタバース上で全ての手続きや相談を行うことができる「メタバース区役所」の構築を進めており、2023年9月から区内の障害者団体の協力による実証実験を実施する等の取組を進めてきた。2024年4月に東京情報デザイン専門職大学と連携して技術的課題の解決に向けたプロジェクトチームを発足して取組を加速させ、2024年6月からはメタバースを活用した一般区民向けの相談・手続き支援サービスの開始を予定している。


2 ロボティクス
　ロボティクスの活用は、労働力不足が続く各分野での活用が期待されている。
　例えば、深刻な医療分野や建設現場等においては、ロボットを遠隔操作することで熟練職員が現場に赴くことなく遠隔地に技術を届けることを可能とし、将来的には複数の現場に一人の熟練者がコミットできるようになる可能性がある。また、ロボットが家事を代行することで家庭内において発生する手間を削減することも期待される。教育現場や介護現場においては、ロボットがコミュニケーション活性の役割を担い、生徒のコミュニケーション能力の向上、入居者とのコミュニケーションや入居者同士のコミュニケーション活性のサポートを可能にする。

ア　遠隔医療（神戸大学、NTTドコモ、NTTコミュニケーションズ、メディカロイド）
　神戸大学、NTTドコモ、NTTコミュニケーションズ、メディカロイドは2023年2月、約500km離れた東京と神戸の2拠点間で、スタンドアローン方式の商用の5Gを活用し、若手医師のロボット手術を熟練医師が遠隔地から支援する実証実験に成功した。高精細な手術映像や音声、ロボット制御の大容量データを、セキュアかつリアルタイムに伝送することで、東京の若手医師が行うロボット手術に対して、神戸の熟練医師が遠隔から手術状況を確認し、会話やロボットの代理操作を行うことが可能となり、遠隔地からの手術支援・指導を実現した。

イ　家庭用ロボット（Preferred Robotics）
　2023年2月にPreferred Roboticsは、専用のキャスター付きシェルフを自動運転で運んでくる家庭用ロボット「カチャカ」を発表。自律移動ロボット「カチャカ」は、キャスター付きの専用シェルフ（ワゴン）の下に潜り込んでドッキングし、目的の場所に移動させたり、元の位置に戻したりできるという家具移動用のロボットで、音声認識に対応しているため、声により指示をすることができる。家庭内のほか、法人での利用としては歯医者や工場、飲食店での利用も増えており、例えば人手不足が深刻な歯医者においては患者に利用した機材を滅菌室へ運ぶ等の工程をカチャカが担うことで、医者がより付加価値の高い業務や患者とのコミュニケーションに時間を割けるようになったほか、工場等においては部品の搬送等に耐久性やセンサを業務ユースに特化した「kachaka Pro」の利用がされている。

ウ　コミュニケーション活性（MIXI等）
　MIXIは、“ペットのように癒やし、家族のように理解してくれる”存在を目指して開発している自律型会話AIロボット「Romi」を渋谷区立渋谷本町学園の協力のもと、2021年11月より小学校1年生から中学校3年生までの教室にテスト導入を行った。
　テスト導入の結果、89%の子供がRomiとコミュニケーションを取ったことが分かる等、子どもの会話力やコミュニケーション能力の発達に寄与することが見込まれている。生徒へのアンケートの結果「休み時間のコミュニケーションが増えた」等の声が上がった。
　また、介護現場での導入も進む。家庭用のコミュニケーションロボット「LOVOT」を提供するGROOVE Xが介護施設で実施した実証実験によると、入居者がコミュニケーションロボットと暮らすことで、入居者の認知機能の低下抑制効果を期待できることが判明した。さらに、生成AIによりロボットへの指示を自然言語で行うことができ、臨機応変な対応をすることが可能となっている。
　人型ロボットPepperの介護向けモデルである「Pepper for Care」は介護現場において、入居者とのコミュニケーションや入居者同士のコミュニケーション活性をサポートする。ソフトバンクロボティクスは2024年2月に人型ロボット「Pepper」の介護向けモデルを対象とした会話アプリをリリースした。ChatGPTを搭載し、自然な会話体験を提供する。「Pepper for Care」はゲーム、歌、体操など豊富な種類のレクリエーションの提供や言語訓練や体を動かす上肢訓練まで搭載しており、顔認証によって個人に特化したリハビリを提供する。


3 自動運転
　日常生活に必要な移動手段の確保が困難な交通弱者や、タクシーやトラックのドライバー不足の中、自動運転により少ないドライバーの場合やドライバー無しでも移動手段を確保できるようになり、あらゆる場所へのアクセスが容易になる。中でも生成AIは自動運転車の開発やテスト、検証段階において活用され、レベル5の実現に向けて自動運転技術の改善を図ることを可能とする。アメリカや中国では自動運転タクシーの商用利用も開始している。無人化が進む一方で、路上で動かなくなる、渋滞を引き起こすことや人身事故などの安全性への懸念や人の仕事が奪われるという懸念の解消が普及の課題の一つとなっている。

ア　交通弱者の移動手段確保 （茨城県境町、BOLDLY、マクニカ 等）
　茨城県境町では、自動運転バスを3台導入し、生活路線バスとして定時・定路線での運行を行っている。境町では、自動車が地域住民の主な交通手段で、最寄りの鉄道駅まで車で約40分かかるなど地域内の公共交通インフラが弱く、高齢者が運転免許を返納したくても、生活のためにできないという課題を抱えており、人手不足に左右されない交通網を整備するために自動運転バスの導入を行った。現在は運転手が乗車して監視するレベル2で走行しており、レベル4での運行を目指している。
　また、福井県永平寺町は第三セクターの会社を設立し、2023年5月より特定条件下における完全自動運転であるレベル4の移動サービスを開始している。限定されたおよそ2キロの区間、最大時速12キロの速度で事故などの緊急事態に備えて事業者が運行状況の監視を行う。加速や減速、ハンドル操作などは車に搭載した専用のシステムがすべてを担う。

イ　ドライバー不足解消（JR西日本、広島県東広島市、広島大学等）
　2023年11月より、JR西日本は、公道で自動運転によるバス高速輸送システム（BRT）の隊列走行実証実験を開始した。JR西条駅と広島大の東広島キャンパスを結ぶ道路に専用のレーンを設けてバスを走らせる。バスが遅れにくく使いやすくなるうえ、運転手不足解消が期待されている。隊列走行時は先頭車に運転士が乗り込み、乗降口の安全確認、ドアの開閉、車内アナウンス、不測の事態が起きたときの緊急停止などを行い、何も問題がなければ運転操作をしないが、異常時には手動で運転するとしている。
